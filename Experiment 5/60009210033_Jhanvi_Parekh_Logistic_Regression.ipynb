{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jyd4wX0JiBCf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import log,dot,exp,shape\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making the classifier\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)"
      ],
      "metadata": {
        "id": "Aiev8vCtil1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the dataframe\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "jFx0zEcAinlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standardizing the dataset for logisitic regression\n",
        "def standardize(X_tr):\n",
        "    for i in range(shape(X_tr)[1]):\n",
        "        X_tr[:,i] = (X_tr[:,i] - np.mean(X_tr[:,i]))/np.std(X_tr[:,i])"
      ],
      "metadata": {
        "id": "A-ZAPaH8ipNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy prediction\n",
        "def F1_score(y,y_hat):\n",
        "    tp,tn,fp,fn = 0,0,0,0\n",
        "    for i in range(len(y)):\n",
        "        if y[i] == 1 and y_hat[i] == 1:\n",
        "            tp += 1\n",
        "        elif y[i] == 1 and y_hat[i] == 0:\n",
        "            fn += 1\n",
        "        elif y[i] == 0 and y_hat[i] == 1:\n",
        "            fp += 1\n",
        "        elif y[i] == 0 and y_hat[i] == 0:\n",
        "            tn += 1\n",
        "    precision = tp/(tp+fp)\n",
        "    recall = tp/(tp+fn)\n",
        "    f1_score = 2*precision*recall/(precision+recall)\n",
        "    return f1_score"
      ],
      "metadata": {
        "id": "X5wqOv5-iqvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main logistic function\n",
        "class LogisticRegression:\n",
        "    def sigmoid(self,z):\n",
        "        sig = 1/(1+exp(-z))\n",
        "        return sig\n",
        "    def initialize(self,X):\n",
        "        weights = np.zeros((shape(X)[1]+1,1))\n",
        "        X = np.c_[np.ones((shape(X)[0],1)),X]\n",
        "        return weights,X\n",
        "    def fit(self,X,y,alpha=0.001,iter=400):\n",
        "        weights,X = self.initialize(X)\n",
        "        def cost(theta):\n",
        "            z = dot(X,theta)\n",
        "            cost0 = y.T.dot(log(self.sigmoid(z)))\n",
        "            cost1 = (1-y).T.dot(log(1-self.sigmoid(z)))\n",
        "            cost = -((cost1 + cost0))/len(y)\n",
        "            return cost\n",
        "        cost_list = np.zeros(iter,)\n",
        "        for i in range(iter):\n",
        "            weights = weights - alpha*dot(X.T,self.sigmoid(dot(X,weights))-np.reshape(y,(len(y),1)))\n",
        "            cost_list[i] = cost(weights)\n",
        "        self.weights = weights\n",
        "        return cost_list\n",
        "    def predict(self,X):\n",
        "        z = dot(self.initialize(X)[1],self.weights)\n",
        "        lis = []\n",
        "        for i in self.sigmoid(z):\n",
        "            if i>0.5:\n",
        "                lis.append(1)\n",
        "            else:\n",
        "                lis.append(0)\n",
        "        return lis\n",
        "\n"
      ],
      "metadata": {
        "id": "khNp9uI-isnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standardizing the dataframe\n",
        "standardize(X_train)\n",
        "standardize(X_test)"
      ],
      "metadata": {
        "id": "__8812N2iuO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# running the logisitic function\n",
        "object1 = LogisticRegression()"
      ],
      "metadata": {
        "id": "mbyndxaZixQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the data\n",
        "model= object1.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "rcx-Py4XizQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training and predicting\n",
        "y_pred = object1.predict(X_test)\n",
        "y_train = object1.predict(X_train)"
      ],
      "metadata": {
        "id": "we9uakgwi1Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the accuracy using the f1score of the splitted dataset\n",
        "f1_score_train = F1_score(y_train,y_train)\n",
        "f1_score_test = F1_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy of the Training Data : \", f1_score_train)\n",
        "print(\"Accuracy of the Testing Data : \",f1_score_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJRO0GWvi21_",
        "outputId": "d23f8375-c9ac-4fe3-a20f-51f4c17a9e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Training Data :  1.0\n",
            "Accuracy of the Testing Data :  0.8349514563106797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# making the classifier\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
        "\n",
        "# splitting the dataframe\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# standardizing the dataset for logistic regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# fitting the model\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# making predictions\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "\n",
        "# evaluating the model\n",
        "f1_score_train = f1_score(y_train, y_pred_train)\n",
        "f1_score_test = f1_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"Accuracy of the Training Data : \", f1_score_train)\n",
        "print(\"Accuracy of the Testing Data : \",f1_score_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWSChIyDMcqB",
        "outputId": "e1712972-a897-4b5b-a19f-ed8a00d08254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Training Data :  0.8642297650130549\n",
            "Accuracy of the Testing Data :  0.8425925925925926\n"
          ]
        }
      ]
    }
  ]
}